{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "0cc28bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "from openpyxl.styles import PatternFill\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa6c6d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "7e8ee8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def mastersheet_data_load():\n",
    "\n",
    "       # read the excel file and see the sheet names\n",
    "       xl_files = pd.ExcelFile(r'..\\landing_zone\\2026\\Hyundia\\2025-11-1 HACC MAF - 20251113.xlsx')\n",
    "\n",
    "       target_sheets = \"Master\"\n",
    "       \n",
    "       if target_sheets in xl_files.sheet_names:\n",
    "              hyundai_master_sheet_df = pd.read_excel(r\"..\\landing_zone\\2026\\Hyundia\\2025-11-1 HACC MAF - 20251113.xlsx\", sheet_name=target_sheets, skiprows=1)\n",
    "\n",
    "       # Keeping only the columns we need\n",
    "\n",
    "       key_columns_to_keep = ['Model \\nYear \\nFrom', 'Model', 'Trim 1', 'Trim 2',\n",
    "              'Trim 3', 'Trim 4', 'Trim 5', 'Trim 6', 'Trim 7', 'Trim 8',\n",
    "              'Accessory Description (EN)', 'Accessory Description (FR)',\n",
    "              'Part\\nNumber', 'DNET', 'MSRP', 'Labour Rate', 'Suggested Labour Hours',\n",
    "              'Suggested Base Retail Price w/labour', 'Comments (EN)', 'Comments (FR)']\n",
    "\n",
    "       hyundai_master_sheet_df = hyundai_master_sheet_df[key_columns_to_keep]\n",
    "\n",
    "\n",
    "       hyundai_master_sheet_df = hyundai_master_sheet_df.dropna(axis=1, how='all')\n",
    "\n",
    "\n",
    "       # changed column names for master_file\n",
    "\n",
    "       column_names_to_change = {\n",
    "       'Model \\nYear \\nFrom': \"Year\", \n",
    "       'Part\\nNumber':'PartNumber', \n",
    "       'Suggested Labour Hours':'Labour Hours',\n",
    "       'Suggested Base Retail Price w/labour':'MSPR w/labour'}\n",
    "\n",
    "       hyundai_master_sheet_df.rename(columns=column_names_to_change, inplace=True)\n",
    "\n",
    "\n",
    "       return hyundai_master_sheet_df \n",
    "\n",
    "hyundai_master_sheet_df = mastersheet_data_load()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee35020e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set standard column names for master file\n",
    "standard_column_names = ['Year', 'Model', 'Trim', 'Description', 'PartNumber',\n",
    "       'DNET', 'MSRP', 'Labour Rate', 'Hours', 'MSPR w/labour',\n",
    "       'Comments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "1c02c6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyundai_model_load():\n",
    "       # load Hyundia model db\n",
    "\n",
    "       hyundai_model_db_df = pd.read_csv(r\"..\\database\\dbs\\Hyundai_models_db.csv\")\n",
    "\n",
    "       # very special changes \n",
    "\n",
    "       mask = (hyundai_model_db_df[\"Year\"] == 2024) & (hyundai_model_db_df[\"Model\"].str.lower() == \"elantra\") & (hyundai_model_db_df[\"Trim\"].str.contains(r\"\\bHybrid Luxury\\b\", case=False))\n",
    "\n",
    "\n",
    "       # Replace \"Hybrid Luxury\" with \"HEV\" in Trim for those records\n",
    "       hyundai_model_db_df.loc[mask, \"Trim\"] = hyundai_model_db_df.loc[mask, \"Trim\"].str.replace(r\"\\bHybrid Luxury\\b\", \"HEV\", case=False, regex=True)\n",
    "\n",
    "       return hyundai_model_db_df\n",
    "\n",
    "hyundai_model_db_df = hyundai_model_load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "cdaca3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def transform_vehicle_data(df):\n",
    "    \"\"\"\n",
    "    Transforms vehicle data by applying trim corrections and model/year-specific changes.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame with columns ['Year', 'Model', 'Trim'].\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Transformed DataFrame.\n",
    "    \"\"\"\n",
    "    \n",
    "    # General trim corrections\n",
    "    data_to_change_on_trim = {\n",
    "        \"Caligraphy\": \"Calligraphy\",\n",
    "        # \"Calli ICE\": \"Calligraphy\",\n",
    "    }\n",
    "    \n",
    "    # Model/year-specific changes\n",
    "    change_for_specific_veh = {\n",
    "        \"Tucson\": {\n",
    "            2026: {\"Ultimate AWD\": \"Utlimate PHEV\"}\n",
    "        },\n",
    "        \"Kona\": {\n",
    "            2026: {\"Pref w/Ult Pkg\": \"Preferred w/Ultimate Pkg\"}\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Santa Fe-specific changes\n",
    "    changes_for_santafe = {\n",
    "        \"Preferred Hybrid\": \"Preferred HEV\",\n",
    "        \"Luxury Hybrid\": \"Luxury HEV\",\n",
    "        \"Calligraphy Hybrid\": \"Calligraphy HEV\"\n",
    "    }\n",
    "    \n",
    "    # 1. Apply general trim corrections\n",
    "    df[\"Trim\"] = df[\"Trim\"].replace(data_to_change_on_trim)\n",
    "    \n",
    "    # 2. Apply model/year-specific changes\n",
    "    for model, year_dict in change_for_specific_veh.items():\n",
    "        for year, trim_changes in year_dict.items():\n",
    "            for old_trim, new_trim in trim_changes.items():\n",
    "                mask = (df[\"Model\"] == model) & (df[\"Year\"] == year) & (df[\"Trim\"] == old_trim)\n",
    "                df.loc[mask, \"Trim\"] = new_trim\n",
    "    \n",
    "    # 3. Apply Santa Fe-specific changes\n",
    "    for old_trim, new_trim in changes_for_santafe.items():\n",
    "        mask = (df[\"Model\"] == \"Santa Fe\") & (df[\"Trim\"] == old_trim)\n",
    "        df.loc[mask, \"Trim\"] = new_trim\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "2d796349",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyundai_model_db_df = transform_vehicle_data(hyundai_model_db_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "046912e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining global assets\n",
    "\n",
    "# tags dictionary for model number mapping\n",
    "\n",
    "tagy = {\n",
    " 'Pref': {'tags': ['Preferred']},\n",
    " 'Urban': {'tags': ['Urban']},\n",
    " 'Calli': {'tags': ['Calligraphy']},\n",
    " 'Calli ICE': {'tags': ['Calligraphy',\"ICE\"]},\n",
    " 'Trend': {'tags': ['Trend']},\n",
    " 'N-Line': {'tags': ['N-Line']},\n",
    " 'Lux': {'tags': ['Luxury']},\n",
    " 'Lux ICE': {'tags': ['Luxury']},\n",
    " 'Ult HEV': {'tags': ['Ultimate', 'HEV']},\n",
    " 'Ult PHEV': {'tags': ['Ultimate', 'PHEV']},\n",
    " 'Ult': {'tags': ['Ultimate']},\n",
    " 'Ess': {'tags': ['Essential']},\n",
    " 'HEV': {'tags': ['HEV']},\n",
    " 'Luxury HEV': {'tags': ['Luxury','HEV']},\n",
    " 'Hybrid Luxury': {'tags': ['Luxury','Hybrid']},\n",
    " 'HEV Luxury': {'tags': ['Luxury','Hybrid']},\n",
    " 'N': {'tags': ['N']},\n",
    " 'N-Line Ult': {'tags': ['N-Line', 'Ult']},\n",
    " 'Advanced': {'tags': ['Advanced']},\n",
    " 'Performance': {'tags': ['Performance']},\n",
    " '2.5T Advanced': {'tags': ['2.5T', 'Advanced']},\n",
    " '2.5T Advanced Plus': {'tags': ['2.5T', 'Advanced', 'Plus']},\n",
    " '2.5T Prestige': {'tags': ['2.5T', 'Prestige']},\n",
    " '3.5T Sport': {'tags': ['3.5T', 'Sport']},\n",
    " '3.5T Sport Plus': {'tags': ['3.5T', 'Sport', 'Plus']},\n",
    " 'Prestige': {'tags': ['Prestige']},\n",
    " '3.3T Advanced': {'tags': ['3.3T', 'Advanced']},\n",
    " '3.3T Sport': {'tags': ['3.3T', 'Sport']},\n",
    " '2.5T Adv': {'tags': ['2.5T', 'Adv']},\n",
    " '3.5T e-SC': {'tags': ['3.5T', 'e-SC']},\n",
    " '3.5T Advanced': {'tags': ['3.5T', 'Advanced']},\n",
    " '3.5T Prestige': {'tags': ['3.5T', 'Prestige']},\n",
    " '3.5T Prestige 7P': {'tags': ['3.5T', 'Prestige', '7P']},\n",
    " 'Trend AWD': {'tags': ['Trend', 'AWD']},\n",
    " 'Pref HEV': {'tags': ['Preferred', 'HEV']},\n",
    " 'Pref HEV w/ Trend': {'tags': ['Preferred', 'HEV','Trend']},\n",
    " 'XRT': {'tags': ['XRT']},\n",
    " 'Ult Calli': {'tags': ['Ultimate', 'Calli']},\n",
    " 'HEV NHL Ed': {'tags': ['HEV', 'NHL', 'Ed']},\n",
    " 'Sport': {'tags': ['Sport']},\n",
    " 'Pref LR': {'tags': ['Preferred', 'Long Range']},\n",
    " '3.5T Sport Plus with eLSD': {'tags': ['3.5T',\n",
    "   'Sport',\n",
    "   'Plus',\n",
    "   'with',\n",
    "   'eLSD']},\n",
    " '2.5T Advanced 5P': {'tags': ['2.5T', 'Advanced', '5P']},\n",
    " '2.5T Advanced Tech Pkg 5P': {'tags': ['2.5T',\n",
    "   'Advanced',\n",
    "   'Tech',\n",
    "   'Pkg',\n",
    "   '5P']},\n",
    " '3.5T Advanced Tech Pkg 7P': {'tags': ['3.5T',\n",
    "   'Advanced',\n",
    "   'Tech',\n",
    "   'Pkg',\n",
    "   '7P']},\n",
    " '3.5T Coupe': {'tags': ['3.5T', 'Coupe']},\n",
    " 'Pref Trend': {'tags': ['Preferred', 'Trend']},\n",
    "#  'Calli ICE': {'tags': ['Calli', 'ICE']},\n",
    " 'Lux HEV': {'tags': ['Luxury', 'HEV']},\n",
    " 'Calli HEV': {'tags': ['Calli', 'HEV']},\n",
    " '2.5T Advanced Tech': {'tags': ['2.5T', 'Advanced', 'Tech']},\n",
    " '3.5T Prestige Black': {'tags': ['3.5T', 'Prestige', 'Black']},\n",
    " '3.5T e-SC Prestige': {'tags': ['3.5T', 'e-SC', 'Prestige']},\n",
    " '3.5T e-SC Prestige Black': {'tags': ['3.5T', 'e-SC', 'Prestige', 'Black']},\n",
    " '3.5T Advanced Tech': {'tags': ['3.5T', 'Advanced', 'Tech']}\n",
    " }\n",
    "\n",
    "\n",
    "missing_model_num_ = pd.DataFrame(columns=[\"Year\", \"Model\", \"Trim\"])\n",
    "missing_keyword = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "a4527b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_trim_columns_in_df(df):\n",
    "    trim_columns = [col for col in df.columns if \"trim\" in col.lower()]\n",
    "    return trim_columns\n",
    "\n",
    "\n",
    "# helper function to show unique values in the master file\n",
    "\n",
    "def show_unique_values(df, columns):\n",
    "    \"\"\"\n",
    "    Display unique values for the specified columns in a DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The DataFrame to analyze.\n",
    "    columns (list): List of column names to check.\n",
    "    \n",
    "    Returns:\n",
    "    dict: A dictionary with column names as keys and unique values as lists.\n",
    "    \"\"\"\n",
    "    unique_dict = {}\n",
    "    for col in columns:\n",
    "        if col in df.columns:\n",
    "            unique_dict[col] = df[col].unique().tolist()\n",
    "            # print(f\"{col}: {df[col].unique().tolist()}\")\n",
    "        else:\n",
    "            unique_dict[col] = \"Column not found\"\n",
    "    return unique_dict\n",
    "\n",
    "\n",
    "\n",
    "def filter_tags(tag_dict, to_remove):\n",
    "    \"\"\"\n",
    "    Removes unwanted values from the 'tags' lists in a dictionary.\n",
    "\n",
    "    Parameters:\n",
    "        tag_dict (dict): Dictionary where each key has a 'tags' list.\n",
    "        to_remove (set): Set of values to remove from the tags.\n",
    "\n",
    "    Returns:\n",
    "        dict: A new dictionary with filtered tags.\n",
    "    \"\"\"\n",
    "    filtered_dict = {}\n",
    "\n",
    "    for key, value in tag_dict.items():\n",
    "        if \"tags\" in value and isinstance(value[\"tags\"], list):\n",
    "            # Keep only tags not in to_remove\n",
    "            new_tags = [tag for tag in value[\"tags\"] if tag not in to_remove]\n",
    "            filtered_dict[key] = {\"tags\": new_tags}\n",
    "\n",
    "    return filtered_dict\n",
    "\n",
    "\n",
    "\n",
    "def create_keyword_dictionary(input_set):\n",
    "    \"\"\"\n",
    "    Takes a set of strings, splits each string by spaces,\n",
    "    and returns a set of unique keywords.\n",
    "    \n",
    "    Parameters:\n",
    "        input_set (set): A set containing strings.\n",
    "    \n",
    "    Returns:\n",
    "        set: A set of unique keywords.\n",
    "    \"\"\"\n",
    "    keyword_dictionary_set = set()\n",
    "    \n",
    "    for value in input_set:\n",
    "        if isinstance(value, str):  # Ensure it's a string\n",
    "            words = value.split()   # Split by spaces\n",
    "            keyword_dictionary_set.update(words)  # Add words to the set\n",
    "    \n",
    "    return keyword_dictionary_set\n",
    "\n",
    "\n",
    "\n",
    "def find_uniq_trimNames_in_df(df):\n",
    "    uniq_trim_list = set()\n",
    "    trim_columns_list = find_trim_columns_in_df(df)\n",
    "    for item in trim_columns_list:\n",
    "        uniq_trim_list.update(df[item].dropna().unique())\n",
    "    return uniq_trim_list\n",
    "\n",
    "def is_tag_available(search_kwd):\n",
    "    if search_kwd not in tagy.keys():\n",
    "        return \"Unavailable\"\n",
    "    \n",
    "    return tagy[search_kwd][\"tags\"]\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "20dc477f",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_trim_list = find_uniq_trimNames_in_df(hyundai_master_sheet_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e912bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "08fb4cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_model_number_by_year_model_with_trim_key_word(year, model, kwd):\n",
    "    \n",
    "    pattern = ''.join(f'(?=.*{kw})' for kw in kwd)  # constructing search keywords pattern \n",
    "    # print(pattern)\n",
    "\n",
    "\n",
    "    res_df = hyundai_model_db_df[\n",
    "        (1==1)\n",
    "        &(hyundai_model_db_df[\"Year\"] == year) \n",
    "\n",
    "        & (hyundai_model_db_df[\"Model\"].str.lower() == model.lower()) \n",
    "        & (hyundai_model_db_df[\"Trim\"].str.contains(pattern, case=False, na=False))\n",
    "    ]\n",
    "\n",
    "    \n",
    "    if len(res_df) <= 0:\n",
    "        return {\"status\": 400,\n",
    "                \"value\":\"\",\n",
    "                    \"msg\": \"No Model number record found. get_model_num_by_YM_wt..()\"}\n",
    "    \n",
    "    response = {\"status\": 200, \n",
    "                \"value\": res_df,\n",
    "                \"msg\": \"Found model number. get_model_num_by_YM_wt..()\"}\n",
    "    return response \n",
    "\n",
    "\n",
    "def get_tags_by_model_and_trim(trim):\n",
    "    # return tag_keywords[trim]\n",
    "    tag_search_results = tagy[trim][\"tags\"]\n",
    "\n",
    "    if len(tag_search_results) <=0:\n",
    "        missing_keyword[trim] = 'Missing kwd'\n",
    "        return tag_search_results\n",
    "    \n",
    "    \n",
    "    return {\"status\": 200,\n",
    "                    \"value\": tag_search_results,\n",
    "                     \"msg\": \"Found tag to use for modelNumber search. get_tag..()\"}\n",
    "\n",
    "def search_hyundai_db_by_model_year_trim(year, model, trim):\n",
    "\n",
    "    search_response = get_tags_by_model_and_trim(trim)\n",
    "    \n",
    "    if search_response[\"status\"] == 400:\n",
    "        return search_response\n",
    "    \n",
    "    tags = search_response[\"value\"]\n",
    "    get_model_nums_search_response = get_model_number_by_year_model_with_trim_key_word(year, model, tags)\n",
    "        \n",
    "    if (get_model_nums_search_response[\"status\"]==400):\n",
    "        missing_model_num_.loc[len(missing_model_num_)] = [year, model, trim]\n",
    "\n",
    "        return get_model_nums_search_response\n",
    "    model_nums = get_model_nums_search_response[\"value\"]\n",
    "\n",
    "    return {\n",
    "            \"status\": 200,\n",
    "            \"value\": model_nums[\"ModelNumber\"].tolist(),\n",
    "            \"msg\": \"Found modelNumbers. search_hyundai_db_by_model_year_trim()\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b969f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "8b1a649d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_extract_all(missing_model_num_):\n",
    "    dataset_summary = pd.DataFrame(columns=['Year', 'Model', 'Trim', 'Record_Count'])\n",
    "    year_model_trim_dict = {}\n",
    "    missing_model_num_ = missing_model_num_.loc[0:0]\n",
    "    missing_keyword = {}\n",
    "\n",
    "    # Looping through the master file by year/model and trim\n",
    "\n",
    "    for year in hyundai_master_sheet_df['Year'].unique():\n",
    "        for model in hyundai_master_sheet_df['Model'].unique():\n",
    "\n",
    "    # filtering to the current iteration for year and Model        \n",
    "            model_df = hyundai_master_sheet_df[\n",
    "                (hyundai_master_sheet_df['Year'] == year) &\n",
    "                (hyundai_master_sheet_df['Model'] == model)\n",
    "            ]\n",
    "            # source_file = hyundai_master_sheet_df[]\n",
    "    # Getting only the name of Trim columns in the vehicle DF\n",
    "            filtered_columns = [col for col in model_df.columns if \"trim\" in col.lower()]\n",
    "\n",
    "    # Looping through unique model df, capturing          \n",
    "            for col in filtered_columns:\n",
    "                trims = model_df[col].dropna().unique().tolist()\n",
    "                # skip empty trim columns\n",
    "                if len(trims) == 0:\n",
    "                    continue            \n",
    "                \n",
    "                trim_name = trims[0]  # grab the trim name in that column. Colum has only one trim name at this point. \n",
    "                \n",
    "                # We are going to create a file for each trim name \n",
    "                # Filter the list searching by trimName and save the list \n",
    "                if trim_name:\n",
    "                    \n",
    "                    # filter by trim name and save a new list\n",
    "                    subset_df = model_df[model_df[col] == trim_name]\n",
    "                    \n",
    "                    # grab all the colms in the subset with the keyword trim\n",
    "                    copy_filtered_columns = [c for c in subset_df.columns if \"trim\" in c.lower()]  # grab all trim columns in the subset\n",
    "                    \n",
    "                    copy_filtered_columns.remove(col)  # drop the current trim column that we want to keep\n",
    "\n",
    "                    subset_df = subset_df.drop(columns=copy_filtered_columns)  #  drop all trim columns except the one we want to keep\n",
    "                    subset_df.rename(columns={col: 'Trim'}, inplace=True)       # rename the current trim column to 'Trim' for clarity\n",
    "                    \n",
    "                    # create copy of the subset dataframe and store both in the dist as english and french versions\n",
    "                    # Identify columns containing \"(EN)\"\n",
    "                    English_columns = [col for col in hyundai_master_sheet_df.columns if \"(EN)\" in col]\n",
    "                    French_columns = [col for col in hyundai_master_sheet_df.columns if \"(FR)\" in col]\n",
    "\n",
    "                    # Initialize nested dict if not exists\n",
    "                    key = (year, model, trim_name)\n",
    "                    year_model_trim_dict.setdefault(key, {\"FR\":pd.DataFrame(), \"EN\":pd.DataFrame()})\n",
    "\n",
    "                    # Remove English columns for French version and vice versa\n",
    "                    # first check if there are any columns to drop\n",
    "\n",
    "                    # get model numbers by year/model/trim\n",
    "                    # they could be one or many, just because\n",
    "                    # some trims come w/t different options\n",
    "                    # and some have different version that came at different times of the year same trims\n",
    "                    \n",
    "                    # Created a list that will get all the model_numbers, they each will have a copy of the data for the particular trim, since they are all handled as unique vehicles.\n",
    "                    modelNum_search_results = search_hyundai_db_by_model_year_trim(year = year, model=model, trim = trim_name)\n",
    "\n",
    "\n",
    "                    if modelNum_search_results[\"status\"] == 400:\n",
    "                        continue\n",
    "                    model_nums = modelNum_search_results[\"value\"]\n",
    "\n",
    "                    # loop through all model numbers and create a copy list for each model number\n",
    "                    for modelnum in model_nums:\n",
    "                        \n",
    "                        if len(English_columns) > 0:\n",
    "                            \n",
    "                            uniq_model_accy_list = subset_df.drop(columns=English_columns)\n",
    "\n",
    "                            # standardize column names for French version\n",
    "                            uniq_model_accy_list.columns = standard_column_names\n",
    "                            \n",
    "                            # get the model_number of the vehicle and add it to the dataframe\n",
    "                            \n",
    "                            uniq_model_accy_list[\"ModelNumber\"] = modelnum\n",
    "                            # year_model_trim_dict[key][\"FR\"].columns = \n",
    "                            year_model_trim_dict[key][\"FR\"] = pd.concat([year_model_trim_dict[key][\"FR\"], uniq_model_accy_list], ignore_index=True)\n",
    "                            \n",
    "                            # then drop some columns to match rate importer format\n",
    "                            # then group all the df for each model and year and finally save them to an excel files\n",
    "            \n",
    "                        if len(French_columns) > 0:\n",
    "                            uniq_model_accy_list = subset_df.drop(columns=French_columns)\n",
    "\n",
    "                            # standardize column names for French version\n",
    "                            uniq_model_accy_list.columns = standard_column_names\n",
    "                            \n",
    "                            # get the model_number of the vehicle and add it to the dataframe\n",
    "                            \n",
    "                            uniq_model_accy_list[\"ModelNumber\"] = modelnum\n",
    "\n",
    "                            year_model_trim_dict[key][\"EN\"] = pd.concat([year_model_trim_dict[key][\"EN\"], uniq_model_accy_list], ignore_index=True)\n",
    "                        \n",
    "                            \n",
    "\n",
    "                        # dataset_summary[(year, model, trim_name)] = len(subset_df)\n",
    "                        dataset_summary.loc[len(dataset_summary)] = [year, model, trim_name, len(subset_df)]\n",
    "\n",
    "                        # print(f\"Year: {year}, Model: {model}, Trim: {trim_name}, Records: {len(subset_df)}\")\n",
    "    return year_model_trim_dict, dataset_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "11082cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_lists_by_model_number(master_dict):\n",
    "    merged_dict = {}\n",
    "\n",
    "    # Merge all DataFrames by model and language\n",
    "    for (year, model, trim_name), value in master_dict.items():\n",
    "        if model not in merged_dict:\n",
    "            merged_dict[model] = {}\n",
    "\n",
    "        for lang, accy_list in value.items():\n",
    "            if lang not in merged_dict[model]:\n",
    "                merged_dict[model][lang] = pd.DataFrame()\n",
    "\n",
    "            merged_dict[model][lang] = pd.concat([merged_dict[model][lang], accy_list], ignore_index=True)\n",
    "\n",
    "    # Filter and rename columns after merging\n",
    "    required_columns = [\"Year\", \"ModelNumber\", \"Description\", \"PartNumber\", \"DNET\", \"MSRP\", \"Hours\", \"Comments\"]\n",
    "    rate_importer_name_column_names = [\"Year\", \"Model\", \"Description\", \"Part\", \"Cost\", \"Price\", \"Hours\", \"Comments\"]\n",
    "\n",
    "    for model, lang_dict in merged_dict.items():\n",
    "        for lang, df in lang_dict.items():\n",
    "            if not df.empty:\n",
    "                existing_cols = [col for col in required_columns if col in df.columns]\n",
    "                filtered_copy = df[existing_cols].copy()\n",
    "                rename_map = {old: new for old, new in zip(required_columns, rate_importer_name_column_names) if old in existing_cols}\n",
    "                filtered_copy.rename(columns=rename_map, inplace=True)\n",
    "                merged_dict[model][lang] = filtered_copy\n",
    "\n",
    "    return merged_dict\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "f914ba29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_upload_report(merged_files_dict):\n",
    "    for keys, values in merged_files_dict.items():\n",
    "        en_cols = len(values[\"EN\"].columns) if \"EN\" in values and isinstance(values[\"EN\"], pd.DataFrame) else \"NA\"\n",
    "        fr_cols = len(values[\"FR\"].columns) if \"FR\" in values and isinstance(values[\"FR\"], pd.DataFrame) else \"NA\"\n",
    "        \n",
    "        print(f\"{keys} : EN: {en_cols}, FR: {fr_cols}\")\n",
    "\n",
    "        # create a report df\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "113320fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_merged_dict_to_excel(merged_dict):\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    filename = f\"Hyundai_Master_ACCY_Ready_To_Load_{timestamp}.xlsx\"\n",
    "    directory = r\"..\\ready_to_upload\\master_files\"\n",
    "    file_path = os.path.join(directory, filename)\n",
    "\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "    with pd.ExcelWriter(file_path, engine='openpyxl') as writer:\n",
    "        for model, lang_dict in merged_dict.items():\n",
    "            for lang, df in lang_dict.items():\n",
    "                sheet_name = f\"{model}_{lang}\"[:31]\n",
    "\n",
    "                if isinstance(df, pd.DataFrame):\n",
    "                    if not df.empty:\n",
    "                        # Write normal sheet\n",
    "                        df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "                    else:\n",
    "                        # Write empty sheet\n",
    "                        pd.DataFrame({\"Message\": [\"No data available\"]}).to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "                        # Apply orange tab color\n",
    "                        ws = writer.book[sheet_name]\n",
    "                        ws.sheet_properties.tabColor = \"FFA500\"  # Orange hex code\n",
    "\n",
    "        # If no sheets were written at all, create a placeholder\n",
    "        if not writer.sheets:\n",
    "            pd.DataFrame({\"Message\": [\"No data available\"]}).to_excel(writer, sheet_name=\"Empty\", index=False)\n",
    "            ws = writer.book[\"Empty\"]\n",
    "            ws.sheet_properties.tabColor = \"FFA500\"  # Orange tab color\n",
    "\n",
    "    return file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7a8571",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "6864262e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# check if each \n",
    "# Get a list of unique model numbers from both Hyundia_db and uniq accy_list dict \n",
    "# store them in vars named db_mdNumCount and file_mdNumCount\n",
    "# Create column is_identical to check if they are identical  \n",
    "# Create column is_equal_count to check if they are equal in length\n",
    "# create column mdNUms_db\n",
    "# create column mdNums_file\n",
    "\n",
    "# Year/Model.countUniqModelNUmber() \n",
    "def data_check(year_model_trim_dict, hyundai_model_db_df): \n",
    "    data_check_report_df = pd.DataFrame(columns=[\"Year\", \"Model\", \"Trim\", \"Lang\", \"is_list_identical?\", \"db_mdNumCount\", \"file_mdNumCount\", \"mdNUms_db\", \"mdNums_file\"])\n",
    "    for (year, model, trim_name),value in year_model_trim_dict.items():\n",
    "    \n",
    "        # # get unique model numbers - files\n",
    "        # FR_uniq_model_nums = value[\"FR\"][\"ModelNumber\"].unique().tolist()\n",
    "        # EN_uniq_model_nums = value[\"EN\"][\"ModelNumber\"].unique().tolist()\n",
    "        \n",
    "        # get unique models numbers from \n",
    "        search_resp = search_hyundai_db_by_model_year_trim(year, model, trim_name)\n",
    "\n",
    "        if search_resp[\"status\"] == 400:\n",
    "            db_mdNumCount = \"Veh Not found in db\"\n",
    "            mdNums_from_db = []\n",
    "        else:\n",
    "            mdNums_from_db = search_resp[\"value\"]\n",
    "            db_mdNumCount = len(mdNums_from_db) \n",
    "        \n",
    "        for lang, accy_list in value.items():\n",
    "            \n",
    "            if \"ModelNumber\" not in accy_list.columns:\n",
    "                uniq_model_nums_list = \"Error: File has no model number column\"\n",
    "                is_indentical_list = False\n",
    "                count_mdNUms_from_accy_list = 0\n",
    "                continue \n",
    "            else:\n",
    "                uniq_model_nums_list = accy_list[\"ModelNumber\"].unique().tolist()\n",
    "                is_indentical_list = (mdNums_from_db == uniq_model_nums_list)\n",
    "                count_mdNUms_from_accy_list = len(uniq_model_nums_list)\n",
    "\n",
    "            new_record_df =  pd.DataFrame(\n",
    "                [[year, \n",
    "                model, \n",
    "                trim_name, \n",
    "                lang,\n",
    "                is_indentical_list, \n",
    "                db_mdNumCount, \n",
    "                count_mdNUms_from_accy_list, \n",
    "                mdNums_from_db, \n",
    "                uniq_model_nums_list]]\n",
    "                , columns=[\"Year\", \"Model\", \"Trim\", \"Lang\", \"is_list_identical?\", \"db_mdNumCount\", \"file_mdNumCount\", \"mdNUms_db\", \"mdNums_file\"])\n",
    "\n",
    "            data_check_report_df = pd.concat([data_check_report_df, new_record_df], ignore_index=True)\n",
    "            \n",
    "    return data_check_report_df\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "a6d33420",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_missing_model_numbers_report_model_db(missing_model_num_, hyundai_model_db_df):\n",
    "    # missing model numbers report \n",
    "    missing_data_report_df = pd.DataFrame(columns=[\"Year\", \"Model\", \"Trim\", \"missingMd#?\", \"Comments\"])\n",
    "\n",
    "    for index, row in missing_model_num_.iterrows():\n",
    "        \n",
    "        # search the veh model in the model number db by year/model/ and trim\n",
    "        \n",
    "        search_result = hyundai_model_db_df[\n",
    "            (1==1)\n",
    "            & (hyundai_model_db_df[\"Year\"] == row[\"Year\"])\n",
    "            & (hyundai_model_db_df[\"Model\"] == row[\"Model\"])\n",
    "            & (hyundai_model_db_df[\"Trim\"] == row[\"Trim\"])\n",
    "            ]\n",
    "\n",
    "        if search_result.empty:\n",
    "            mdNUmStatus = True\n",
    "        else:\n",
    "            mdNUmStatus = False\n",
    "\n",
    "        new_row = pd.DataFrame(\n",
    "                                [[row[\"Year\"], row[\"Model\"],row[\"Trim\"], mdNUmStatus, \"Missing model Number.\"]], \n",
    "                                columns=[\"Year\", \"Model\", \"Trim\", \"missingMd#?\", \"Comments\"]\n",
    "                            )  \n",
    "        # concat dfs\n",
    "        missing_data_report_df = pd.concat([missing_data_report_df, new_row], ignore_index=True)\n",
    "    \n",
    "    return missing_data_report_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03fc089",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f00d5ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "52792de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Prepare the output filename with timestamp\n",
    "# timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "# filename = \"Hyundai_ACCY_load_report_{timestamp}.csv\"\n",
    "# directory = r\"..\\reports_log\\Hyundai\\data_load\"\n",
    "# output_path = os.path.join(directory, filename)\n",
    "\n",
    "# data_load_report_check_df.to_csv(output_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "9d25fa13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tags_for_veh_trims(df):\n",
    "   # Decomposing trim to enable tagging\n",
    "   all_trim_names= df[\"Trim\"].unique().tolist()\n",
    "   extracted_dict = {}\n",
    "   kwds_to_drop = [\"w/t\", \"with\"]\n",
    "   for item in all_trim_names:\n",
    "      if \" \" not in item:\n",
    "         parts = [item]\n",
    "\n",
    "      else:\n",
    "         parts = item.split()\n",
    "      \n",
    "      extracted_dict[item]= {\"tags\" :parts} \n",
    "\n",
    "   return extracted_dict\n",
    "# create_tags_for_veh_trims(dataset_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "575e9b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaned_models.to_csv(r'..\\database\\dbs\\Hyundai_models_db.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "75ea7c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_tags = filter_tags(tagy, (model_num_db_kwrd - master_df_kwdrs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "5d859d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_missing_modelNums(df):\n",
    "    # dataset_summary[dataset_summary[\"Trim\"].str.contains(\"w/\")]\n",
    "    # counter = 0\n",
    "    missing_model_numbers = pd.DataFrame(columns=[\"Year\", \"Model\", \"Trim\"])\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        Model_numbers_output = search_hyundai_db_by_model_year_trim(row.Year, row.Model, row.Trim)\n",
    "        \n",
    "        if 0 >= len(Model_numbers_output):\n",
    "            # print(f\"Year : {row.Year}, Model : {row.Model}, Trim : {row.Trim} -> No Model_numbers\")\n",
    "            missing_model_numbers.loc[len(missing_model_numbers)] = [row.Year, row.Model, row.Trim]\n",
    "    return missing_model_numbers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "6bd43ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "year_model_trim_dict, dataset_summary = data_extract_all(missing_model_num_)\n",
    "merged_files_dict = merge_lists_by_model_number(year_model_trim_dict)\n",
    "# save_merged_dict_to_excel(merged_dict= merged_files_dict)\n",
    "# find_missing_modelNums(dataset_summary)\n",
    " \n",
    "data_load_report_check_df = data_check(year_model_trim_dict, hyundai_model_db_df)\n",
    "missing_data_report = check_missing_model_numbers_report_model_db(missing_model_num_, hyundai_model_db_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "bbdb4f97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palisade : EN: 8, FR: 8\n",
      "Tucson : EN: 8, FR: 8\n",
      "Santa Cruz : EN: 8, FR: 8\n",
      "Elantra : EN: 8, FR: 8\n",
      "Ioniq 6 : EN: 8, FR: 8\n",
      "Kona : EN: 8, FR: 8\n",
      "Kona EV : EN: 8, FR: 8\n",
      "Venue : EN: 8, FR: 8\n",
      "Ioniq 5 : EN: 8, FR: 8\n",
      "GV60 : EN: 0, FR: 0\n",
      "GV70 : EN: 0, FR: 0\n",
      "GV70 EV : EN: 0, FR: 0\n",
      "G70 : EN: 0, FR: 0\n",
      "G80 EV : EN: 0, FR: 0\n",
      "G80 : EN: 0, FR: 0\n",
      "G90 : EN: 0, FR: 0\n",
      "GV80 : EN: 0, FR: 0\n",
      "Sonata : EN: 8, FR: 8\n",
      "Santa Fe : EN: 8, FR: 8\n",
      "GV80 Coupe : EN: 0, FR: 0\n",
      "Ioniq 9 : EN: 8, FR: 8\n"
     ]
    }
   ],
   "source": [
    "get_upload_report(merged_files_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "c19ca250",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Palisade', 'GV60', 'GV70', 'GV70 EV', 'G70', 'G80 EV', 'G80',\n",
       "       'G90', 'GV80', 'Santa Fe', 'GV80 Coupe', 'Tucson', 'Santa Cruz',\n",
       "       'Kona EV', 'Sonata'], dtype=object)"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_data_report[\"Model\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "a7019ded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Model</th>\n",
       "      <th>Trim</th>\n",
       "      <th>missingMd#?</th>\n",
       "      <th>Comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024</td>\n",
       "      <td>Palisade</td>\n",
       "      <td>Calli</td>\n",
       "      <td>True</td>\n",
       "      <td>Missing model Number.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2026</td>\n",
       "      <td>Palisade</td>\n",
       "      <td>Calli ICE</td>\n",
       "      <td>True</td>\n",
       "      <td>Missing model Number.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>2024</td>\n",
       "      <td>Palisade</td>\n",
       "      <td>Calli</td>\n",
       "      <td>True</td>\n",
       "      <td>Missing model Number.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>2026</td>\n",
       "      <td>Palisade</td>\n",
       "      <td>Calli ICE</td>\n",
       "      <td>True</td>\n",
       "      <td>Missing model Number.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>2024</td>\n",
       "      <td>Palisade</td>\n",
       "      <td>Calli</td>\n",
       "      <td>True</td>\n",
       "      <td>Missing model Number.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>2026</td>\n",
       "      <td>Palisade</td>\n",
       "      <td>Calli ICE</td>\n",
       "      <td>True</td>\n",
       "      <td>Missing model Number.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>2024</td>\n",
       "      <td>Palisade</td>\n",
       "      <td>Calli</td>\n",
       "      <td>True</td>\n",
       "      <td>Missing model Number.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>2026</td>\n",
       "      <td>Palisade</td>\n",
       "      <td>Calli ICE</td>\n",
       "      <td>True</td>\n",
       "      <td>Missing model Number.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Year     Model       Trim missingMd#?               Comments\n",
       "0    2024  Palisade      Calli        True  Missing model Number.\n",
       "46   2026  Palisade  Calli ICE        True  Missing model Number.\n",
       "84   2024  Palisade      Calli        True  Missing model Number.\n",
       "130  2026  Palisade  Calli ICE        True  Missing model Number.\n",
       "168  2024  Palisade      Calli        True  Missing model Number.\n",
       "214  2026  Palisade  Calli ICE        True  Missing model Number.\n",
       "252  2024  Palisade      Calli        True  Missing model Number.\n",
       "298  2026  Palisade  Calli ICE        True  Missing model Number."
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_data_report[missing_data_report[\"Model\"]==\"Palisade\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "19d66a32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Calligraphy']"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_tag_available(\"Calli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "669b8549",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 400,\n",
       " 'value': '',\n",
       " 'msg': 'No Model number record found. get_model_num_by_YM_wt..()'}"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_hyundai_db_by_model_year_trim(2026, \"Palisade\", \"Calli ICE\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201c4751",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>ModelNumber</th>\n",
       "      <th>Model</th>\n",
       "      <th>Trim</th>\n",
       "      <th>Source_sheets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2026</td>\n",
       "      <td>PACW7K3FULCA</td>\n",
       "      <td>Palisade</td>\n",
       "      <td>3.5L Ultimate Calligraphy 7-Pass</td>\n",
       "      <td>2026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>2026</td>\n",
       "      <td>PAHW7G2DULCH</td>\n",
       "      <td>Palisade</td>\n",
       "      <td>2.5T Ultimate Calligraphy HEV 7-Pass</td>\n",
       "      <td>2026</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Year   ModelNumber     Model                                  Trim  \\\n",
       "48  2026  PACW7K3FULCA  Palisade      3.5L Ultimate Calligraphy 7-Pass   \n",
       "51  2026  PAHW7G2DULCH  Palisade  2.5T Ultimate Calligraphy HEV 7-Pass   \n",
       "\n",
       "   Source_sheets  \n",
       "48          2026  \n",
       "51          2026  "
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "hyundai_model_db_df[\n",
    "                    (hyundai_model_db_df[\"Year\"]==2026) \n",
    "                    & \n",
    "                    (hyundai_model_db_df[\"Model\"]==\"Palisade\")\n",
    "                    &(hyundai_model_db_df[\"Trim\"].str.contains(\"Calligraphy\", case=False))\n",
    "                    # &(hyundai_model_db_df[\"Trim\"].str.contains(\"Ultimate AWD\", case=False))\n",
    "                    ]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e702c79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
